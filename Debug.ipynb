{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5d78bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.distributed as dist\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "from mmcv.utils import get_git_hash\n",
    "from mmcv.utils import TORCH_VERSION, Registry, build_from_cfg, digit_version\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import init_random_seed, set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import (collect_env, get_device, get_root_logger,\n",
    "                         setup_multi_processes, update_data_root)\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78991bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() != 'Windows':\n",
    "    # https://github.com/pytorch/pytorch/issues/973\n",
    "    import resource\n",
    "    rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "    base_soft_limit = rlimit[0]\n",
    "    hard_limit = rlimit[1]\n",
    "    soft_limit = min(max(4096, base_soft_limit), hard_limit)\n",
    "    resource.setrlimit(resource.RLIMIT_NOFILE, (soft_limit, hard_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb3675ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_full = Config.fromfile('/home/rohit/Projects/Face_Det/Models/YuNet/custom_train/libfacedetection.train/configs/yunet_n.py')\n",
    "update_data_root(cfg_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c3c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cfg_full.data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef0cc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'RetinaFaceDataset', 'ann_file': 'data/labelv2/train/labelv2.txt', 'img_prefix': '', 'pipeline': [{'type': 'LoadImageFromFile', 'to_float32': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_keypoints': False}, {'type': 'RandomSquareCrop', 'crop_choice': [0.5, 0.7, 0.9, 1.1, 1.3, 1.5]}, {'type': 'Resize', 'img_scale': (640, 640), 'keep_ratio': False}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [0.0, 0.0, 0.0], 'std': [1.0, 1.0, 1.0], 'to_rgb': False}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore', 'gt_keypointss']}]}\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71c912f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets.dataset_wrappers import (ClassBalancedDataset, ConcatDataset,\n",
    "                                   MultiImageMixDataset, RepeatDataset)\n",
    "\n",
    "if isinstance(cfg, (list, tuple)):\n",
    "    print(1)\n",
    "elif cfg['type'] == 'ConcatDataset':\n",
    "    print(2)\n",
    "elif cfg['type'] == 'RepeatDataset':\n",
    "    print(3)\n",
    "elif cfg['type'] == 'ClassBalancedDataset':\n",
    "    print(4)\n",
    "elif cfg['type'] == 'MultiImageMixDataset':\n",
    "    print(5)\n",
    "elif isinstance(cfg.get('ann_file'), (list, tuple)):\n",
    "    print(6)\n",
    "else:\n",
    "    print(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9be92617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, cfg):\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "        f = open(cfg['ann_file'])\n",
    "        for i in (f):\n",
    "            if i[0] == '#':\n",
    "                self.img_paths.append(i.split(' ')[1])\n",
    "            else:\n",
    "                temp = []\n",
    "                while i[0] != 0:\n",
    "                    temp.append(i.split(' ')[:4])\n",
    "                self.labels.append(temp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9adae108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['730', '377', '946', '674']\n"
     ]
    }
   ],
   "source": [
    "cfg['ann_file']\n",
    "f = open(cfg['ann_file'])\n",
    "for i in (f):\n",
    "    if  i[0]!= '#':\n",
    "        print(i.split(' ')[:4])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addf1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# /home/rohit/Projects/Face_Det/Models/YuNet/custom_train/libfacedetection.train/data/train/500.jpg 1080 1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"/home/rohit/Projects/Face_Det/Models/YuNet/custom_train/libfacedetection.train/data/labelv2/train/labelv2.txt\", \"r\")\n",
    "for i in f:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ecb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
